# ðŸš€ Recursos AvanÃ§ados OpenAI - ExpiWish

## 1. Sistema de Reranking Multi-Signal

**Arquivo**: `lib/reranking-service.ts`

### O que Ã©?
Sistema que combina mÃºltiplos sinais para reordenar candidatos e melhorar precisÃ£o da seleÃ§Ã£o de keywords/problemas.

### Sinais Utilizados (com pesos):
1. **Embedding Score (40%)**: Similaridade semÃ¢ntica base
2. **Structural Score (30%)**: CoerÃªncia departamento-keyword (validaÃ§Ã£o estrutural)
3. **Frequency Score (15%)**: Prior probability (keywords mais usadas tÃªm prioridade)
4. **Context Score (15%)**: AnÃ¡lise sintÃ¡tica da frase (palavras presentes, negaÃ§Ã£o/afirmaÃ§Ã£o)

### Como funciona:
```typescript
// Entrada: candidatos do embedding + texto do usuÃ¡rio
const rankedCandidates = rerankCandidates(
  candidates,           // Array de candidatos com similarity_score
  userText,            // Texto original do feedback
  requiredDepartment   // Departamento especÃ­fico (opcional)
);

// SaÃ­da: candidatos reordenados com score combinado
// [
//   { label: "A&B - ServiÃ§o", final_score: 0.82, reranking_signals: {...} },
//   { label: "A&B - Gastronomia", final_score: 0.71, ... }
// ]
```

### Vantagens:
- **PenalizaÃ§Ã£o forte**: Keywords com departamento errado estruturalmente recebem score 0
- **Aprendizado online**: FrequÃªncia atualizada dinamicamente com `updateKeywordFrequency()`
- **Contexto linguÃ­stico**: Detecta negaÃ§Ãµes ("nÃ£o foi bom") e ajusta score
- **Debugging**: Logs detalhados de top 3 com breakdown de scores

### IntegraÃ§Ã£o:
```typescript
// No analyze-feedback route, apÃ³s buscar candidatos:
const candidates = await taxonomyService.findCandidates(text, "keywords", 10);
const rerankedCandidates = rerankCandidates(candidates, text, issue.department);

// Usar top 1 reranked ao invÃ©s de top 1 original
const bestKeyword = rerankedCandidates[0];
```

---

## 2. Structured Outputs (JSON Schema Nativo)

**Arquivo**: `lib/structured-outputs-schema.ts`

### O que Ã©?
Feature nativa do GPT-4 que **garante 100% de conformidade** com JSON Schema, eliminando parsing errors.

### DiferenÃ§a vs Function Calling tradicional:
| Feature | Function Calling | Structured Outputs |
|---------|------------------|-------------------|
| Conformidade JSON | ~95% (ocasionais erros) | 100% garantido |
| Parsing errors | Requer try/catch | Zero erros |
| Performance | Bom | Melhor (menos retries) |
| Tipos complexos | Limitado | anyOf, allOf, nested objects |
| ValidaÃ§Ã£o enums | Manual | AutomÃ¡tica |

### Schemas DisponÃ­veis:

#### 1. `feedbackClassificationSchema`
Schema completo com metadata de qualidade:
```typescript
{
  sentiment: 1-5,
  has_suggestion: boolean,
  suggestion_type: enum,
  issues: [
    {
      keyword: string,
      department: string,
      problem: string,
      problem_detail: string,
      confidence: 0-1  // NOVO: confianÃ§a da classificaÃ§Ã£o
    }
  ],
  classification_quality: {  // NOVO: metadata de qualidade
    overall_confidence: 0-1,
    ambiguity_level: "low" | "medium" | "high",
    requires_human_review: boolean,
    reasoning: string  // ExplicaÃ§Ã£o da decisÃ£o
  }
}
```

**Vantagens**:
- Detecta classificaÃ§Ãµes incertas automaticamente
- Fornece reasoning para auditoria
- Permite filtrar feedbacks que precisam revisÃ£o humana

#### 2. `suggestionAnalysisSchema`
Schema especializado para sugestÃµes:
```typescript
{
  suggestion_category: "nova_amenidade" | "melhoria_servico" | ...,
  feasibility: "easy" | "moderate" | "difficult",
  impact_potential: "low" | "medium" | "high",
  departments_involved: ["A&B", "Tecnologia"],
  extracted_suggestion: "Adicionar opÃ§Ãµes veganas no cafÃ© da manhÃ£"
}
```

**Uso**: Pipeline em 2 etapas quando `has_suggestion = true`:
1. ClassificaÃ§Ã£o geral (schema principal)
2. AnÃ¡lise aprofundada da sugestÃ£o (schema de sugestÃ£o)

#### 3. `contextualSentimentSchema`
Schema para sentimento contextual quando ambÃ­guo:
```typescript
{
  sentiment_breakdown: {
    positive_aspects: ["LocalizaÃ§Ã£o Ã³tima", "Staff atencioso"],
    negative_aspects: ["Quarto sujo", "Demora no check-in"],
    neutral_aspects: ["PreÃ§o na mÃ©dia"]
  },
  dominant_sentiment: 2,  // Insatisfeito (negativos dominam)
  sentiment_justification: "Apesar de elogiar localizaÃ§Ã£o..."
}
```

**Uso**: Quando `classification_quality.ambiguity_level === "high"`, fazer segunda chamada para anÃ¡lise contextual.

### Como Integrar:

```typescript
import { feedbackClassificationSchema, validateFeedbackClassification } from './structured-outputs-schema';

// No openai-client.ts, substituir function calling por response_format:
const completion = await openai.chat.completions.create({
  model: "gpt-4o-mini",
  messages: [{ role: "user", content: prompt }],
  response_format: feedbackClassificationSchema,  // â† Usar schema
  temperature: 0.2
});

// Parse sempre bem-sucedido (garantido):
const result = JSON.parse(completion.choices[0].message.content);

// ValidaÃ§Ã£o adicional (double-check):
if (!validateFeedbackClassification(result)) {
  throw new Error("Schema validation failed");
}

// Type-safe:
const classification: FeedbackClassification = result;
console.log(`Confidence: ${classification.classification_quality.overall_confidence}`);
```

### BenefÃ­cios Imediatos:
1. **Zero parsing errors**: Elimina try/catch de JSON.parse
2. **Type-safety**: Interfaces TypeScript geradas automaticamente
3. **Metadata de qualidade**: Saber quando classificaÃ§Ã£o Ã© incerta
4. **Debugging melhorado**: Reasoning field explica decisÃµes
5. **Pipeline em etapas**: Schemas especializados para sugestÃµes e ambiguidade

---

## 3. Outras Features OpenAI Recomendadas

### A. Fine-tuning GPT-4 (gpt-4o-mini-2024-07-18)

**Quando usar**:
- Depois de coletar 500+ feedbacks classificados manualmente
- Para ensinar padrÃµes especÃ­ficos do domÃ­nio hoteleiro
- Reduzir dependÃªncia de prompts longos

**Processo**:
1. Exportar feedbacks + classificaÃ§Ãµes corretas no formato JSONL
2. Upload dataset via API: `openai.files.create()`
3. Criar fine-tuning job: `openai.fine_tuning.jobs.create()`
4. Treinar ~2-4 horas
5. Usar modelo customizado: `model: "ft:gpt-4o-mini:org:model_id"`

**Vantagens**:
- 30-50% melhoria na precisÃ£o para domÃ­nio especÃ­fico
- LatÃªncia menor (prompts mais curtos)
- Custo reduzido a longo prazo

### B. Batch API (50% de desconto)

**Quando usar**:
- ImportaÃ§Ãµes grandes de CSV/XLSX
- Reprocessamento de histÃ³rico
- AnÃ¡lises nÃ£o urgentes

**Como funciona**:
```typescript
// Criar arquivo batch (JSONL):
const batchRequests = feedbacks.map(f => ({
  custom_id: f.id,
  method: "POST",
  url: "/v1/chat/completions",
  body: {
    model: "gpt-4o-mini",
    messages: [{ role: "user", content: `Classifique: ${f.text}` }],
    response_format: feedbackClassificationSchema
  }
}));

// Upload e executar:
const batchFile = await openai.files.create({
  file: Buffer.from(batchRequests.map(r => JSON.stringify(r)).join('\n')),
  purpose: "batch"
});

const batch = await openai.batches.create({
  input_file_id: batchFile.id,
  endpoint: "/v1/chat/completions",
  completion_window: "24h"
});

// Polling atÃ© completar:
while (batch.status !== "completed") {
  await sleep(60000);
  batch = await openai.batches.retrieve(batch.id);
}

// Download resultados:
const outputFile = await openai.files.content(batch.output_file_id);
```

**Vantagens**:
- 50% de desconto vs API sÃ­ncrona
- Processa milhares de feedbacks overnight
- Retries automÃ¡ticos

### C. text-embedding-3-large (Embeddings Melhores)

**Atual**: `text-embedding-3-small` (1536 dimensÃµes)  
**Upgrade**: `text-embedding-3-large` (3072 dimensÃµes)

**ComparaÃ§Ã£o**:
| MÃ©trica | small | large |
|---------|-------|-------|
| DimensÃµes | 1536 | 3072 |
| PrecisÃ£o MTEB | 62.3% | 64.6% |
| Custo/1M tokens | $0.02 | $0.13 |
| LatÃªncia | ~100ms | ~150ms |

**Quando vale a pena**:
- Feedbacks muito curtos/ambÃ­guos
- Necessidade de mÃ¡xima precisÃ£o
- Budget permite (6.5x mais caro)

**Como testar**:
```typescript
// Em embeddings-service.ts:
const embedding = await openai.embeddings.create({
  model: "text-embedding-3-large",  // â† Trocar aqui
  input: text
});
```

### D. Logprobs (Debugging de Incerteza)

**O que Ã©**: Retorna log-probabilidades dos tokens gerados, revelando incerteza do modelo.

**Como usar**:
```typescript
const completion = await openai.chat.completions.create({
  model: "gpt-4o-mini",
  messages: [...],
  logprobs: true,
  top_logprobs: 5  // Top 5 tokens mais provÃ¡veis em cada posiÃ§Ã£o
});

// Analisar incerteza:
const avgLogProb = completion.choices[0].logprobs.content
  .map(t => t.logprob)
  .reduce((a, b) => a + b, 0) / completion.choices[0].logprobs.content.length;

if (avgLogProb < -1.5) {
  console.warn("ClassificaÃ§Ã£o incerta - modelo hesitante");
}
```

**Uso prÃ¡tico**: Detectar quando modelo estÃ¡ "adivinhando" vs confiante.

---

## 4. Roadmap de ImplementaÃ§Ã£o

### Fase 1: Melhorias Imediatas (1-2 dias)
- [x] Sistema de reranking multi-signal
- [x] Structured outputs schemas
- [ ] Integrar reranking no analyze-feedback route
- [ ] Migrar de function calling para structured outputs

### Fase 2: Metadata de Qualidade (3-5 dias)
- [ ] Adicionar campos de confianÃ§a em todas classificaÃ§Ãµes
- [ ] Dashboard para feedbacks com `requires_human_review: true`
- [ ] Sistema de feedback loop (usuÃ¡rios corrigem classificaÃ§Ãµes)

### Fase 3: Fine-tuning (1-2 semanas)
- [ ] Coletar 500+ feedbacks classificados manualmente
- [ ] Preparar dataset JSONL
- [ ] Treinar modelo customizado
- [ ] A/B test: modelo base vs fine-tuned

### Fase 4: Batch Processing (1 semana)
- [ ] Implementar pipeline batch para importaÃ§Ãµes grandes
- [ ] Sistema de queueing para anÃ¡lises overnight
- [ ] ReduÃ§Ã£o de 50% no custo de processamento em lote

---

## 5. Monitoramento e MÃ©tricas

### MÃ©tricas Recomendadas:
1. **Reranking Impact**: % de vezes que top 1 muda apÃ³s reranking
2. **Confidence Distribution**: Histograma de `overall_confidence`
3. **Human Review Rate**: % de feedbacks com `requires_human_review: true`
4. **Correction Rate**: % de classificaÃ§Ãµes corrigidas manualmente
5. **Structural Violations**: Quantas vezes validaÃ§Ã£o estrutural pega erros

### Dashboard Sugerido:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“Š AI Quality Metrics (Ãšltimos 30 dias)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total ClassificaÃ§Ãµes: 1,243                 â”‚
â”‚ Confidence MÃ©dia: 0.87                      â”‚
â”‚ Reranking Changes: 18.3%                    â”‚
â”‚ Structural Corrections: 42 (3.4%)           â”‚
â”‚ Human Review Queue: 37 (3.0%)               â”‚
â”‚                                              â”‚
â”‚ [Ver Feedbacks Incertos] [Export MÃ©tricas] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Custos Estimados

### Setup Atual (text-embedding-3-small + gpt-4o-mini):
- Embedding: 1M tokens = $0.02
- Classification: 1M tokens = $0.15
- Custo mÃ©dio por feedback: ~$0.0003

### Com Melhorias:
| Feature | Impacto no Custo | Vale a pena? |
|---------|------------------|--------------|
| Structured Outputs | 0% | âœ… Sim (zero custo extra) |
| Reranking | 0% | âœ… Sim (local, sem API calls) |
| text-embedding-3-large | +550% | âš ï¸ SÃ³ se precisÃ£o crÃ­tica |
| Batch API | -50% | âœ… Sim (importaÃ§Ãµes grandes) |
| Fine-tuning | -20% a longo prazo | âœ… Sim (apÃ³s 10k+ feedbacks) |

### RecomendaÃ§Ã£o:
1. Implementar structured outputs (grÃ¡tis, grande benefÃ­cio)
2. Usar batch API para importaÃ§Ãµes (50% desconto)
3. Aguardar mais dados para fine-tuning
4. Evitar embedding-3-large por enquanto (custo alto)

---

## 7. Links e DocumentaÃ§Ã£o

- [Structured Outputs Guide](https://platform.openai.com/docs/guides/structured-outputs)
- [Fine-tuning GPT-4](https://platform.openai.com/docs/guides/fine-tuning)
- [Batch API](https://platform.openai.com/docs/guides/batch)
- [Embeddings Comparison](https://openai.com/index/new-embedding-models-and-api-updates/)
- [Function Calling vs Structured Outputs](https://platform.openai.com/docs/guides/function-calling)
